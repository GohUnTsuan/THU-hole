{"code": 0, "data": [{"cid": 500572, "deleted": false, "image_metadata": {}, "is_dz": false, "name": "Alice", "pid": 104177, "reply_to": -1, "tag": null, "text": "?NSFW?", "timestamp": 1603982388, "type": "text", "url": ""}, {"cid": 500810, "deleted": false, "image_metadata": {}, "is_dz": false, "name": "Bob", "pid": 104177, "reply_to": -1, "tag": null, "text": "Re Alice: 因为爬的东西NSFW", "timestamp": 1603985537, "type": "text", "url": ""}, {"cid": 501913, "deleted": false, "image_metadata": {}, "is_dz": false, "name": "Carol", "pid": 104177, "reply_to": -1, "tag": null, "text": "请问这个出来的结果是啥", "timestamp": 1604030784, "type": "text", "url": ""}, {"cid": 502149, "deleted": false, "image_metadata": {}, "is_dz": false, "name": "Dave", "pid": 104177, "reply_to": -1, "tag": null, "text": "Re : 哈哈，原洞主来致谢！马上试试\n", "timestamp": 1604035596, "type": "text", "url": ""}, {"cid": 502216, "deleted": false, "image_metadata": {}, "is_dz": false, "name": "Dave", "pid": 104177, "reply_to": -1, "tag": null, "text": "大佬就是大佬，果然能用。不过这个是要一页一页的下载。理论上是不是可以再写一个脚本，调用这个脚本，就可爬全站了。 比如从这个页面开始： https://www.xiurenji.com/XiuRen/index3.html", "timestamp": 1604036894, "type": "text", "url": ""}, {"cid": 502439, "deleted": false, "image_metadata": {}, "is_dz": false, "name": "Eve", "pid": 104177, "reply_to": -1, "tag": null, "text": "请问dz是如何在树洞里这样传代码的鸭 ", "timestamp": 1604044197, "type": "text", "url": ""}, {"cid": 502514, "deleted": false, "image_metadata": {}, "is_dz": false, "name": "Dave", "pid": 104177, "reply_to": -1, "tag": null, "text": "Re Eve: 双击洞主 复制原文", "timestamp": 1604045297, "type": "text", "url": ""}, {"cid": 502655, "deleted": false, "image_metadata": {}, "is_dz": true, "name": "洞主", "pid": 104177, "reply_to": -1, "tag": null, "text": "Re Dave: 这样太多了，这个脚本下载一个就花几分钟能有四五十张图，想爬所有的，一方面存储空间不知道有没有问题，另一方面不知道网站是否会监测爬虫", "timestamp": 1604047520, "type": "text", "url": ""}, {"cid": 502658, "deleted": false, "image_metadata": {}, "is_dz": false, "name": "Carol", "pid": 104177, "reply_to": -1, "tag": null, "text": "Re Dave: 这个下载了个啥。。为什么我运行了没反应。。", "timestamp": 1604047570, "type": "text", "url": ""}], "post": {"deleted": false, "image_metadata": {}, "likenum": 17, "pid": 104177, "reply": 9, "tag": "NSFW", "text": "#NSFW\n#103422\n\n既然有人提到了，那就做一下吧。复制下面代码到一个py文件然后运行即可。\n\npython2 通过测试；注意事项：\n- 如果是 python3，需要修改一下库的导入；\n- 如果没有 beautifulsoup4 库，需要先安装。\n\n这些注意事项都在文件头的注释里写了，照着做就行。注意如果 python3 可能是 pip3 才能安装 beautifulsoup4 库给 python3。\n\n- \n\n``` python\nfrom sys import argv\nfrom random import uniform\nfrom time import sleep\nfrom os.path import join, basename, expanduser\n# If Python3: [from urllib.request import urlopen, urlretrieve]\nfrom urllib import urlopen, urlretrieve\n# Run: [pip install beautifulsoup4]\nfrom bs4 import BeautifulSoup\n\nif len(argv) < 3:\n    print(\"[Usage]   python {} <url> <local dir>\".format(argv[0]))\n    print(\"[Example] python {} https://www.xiurenji.com/YouMi/6779.html ./YouMi/\".format(argv[0]))\n    exit(1)\n\nrooturl = \"https://www.xiurenji.com\"\ntarget = argv[1]\nbasedir = argv[2]\n\nres = urlopen(target)\nbuf = res.read()\nsoup = BeautifulSoup(buf,\"html.parser\",from_encoding=\"utf-8\")\nnav = soup.find(\"div\", class_=\"page\")\npages = []\n\nfor link in nav.children:\n    pages.append(link.get(\"href\"))\npages = [rooturl + i for i in pages]\n\nfor i in range(len(pages)):\n    page = pages[i]\n    print(\n        \"{}/{} Downloading from {}\"\n        .format(i+1, len(pages), page)\n    )\n    imgurls = []\n    sleep(uniform(0.5, 2))\n    res = urlopen(page)\n    buf = res.read()\n    soup = BeautifulSoup(buf,\"html.parser\",from_encoding=\"utf-8\")\n    imgs = soup.find(\"div\", class_=\"img\").find_all(\"img\")\n    for img in imgs:\n        imgurls.append(img.get(\"src\"))\n    imgurls = [rooturl + i for i in imgurls]\n    for j in range(len(imgurls)):\n        imgurl = imgurls[j]\n        print(\n            \"  {}/{} Downloading image {}\"\n            .format(j+1, len(imgurls), basename(imgurl))\n        )\n        imgpath = join(basedir, basename(imgurl))\n        sleep(uniform(0.5, 2))\n        urlretrieve(imgurl, imgpath)\n\n```", "timestamp": 1603982224, "type": "text", "updated_at": 1606782637, "url": "", "vote": {}}}