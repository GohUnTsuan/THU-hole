{"code": 0, "data": [], "post": {"deleted": false, "image_metadata": {}, "likenum": 2, "pid": 104789, "reply": 0, "tag": "NSFW", "text": "#NSFW#\n#兔女郎与猫娘的日常#\n我是兔女郎与猫娘，#104574里说的代码我写好了……丑话先说在前面，dz没有接受过系统训练，学的专业和编程不沾边，学python依靠的全是b站上的教程和一颗lsp的心。这是我第一次写代码给别人用，肯定会各种bug满天飞，我尽量及时回复质疑，保证虚心接受批评。\n另外我发现树洞贴代码，如果一行代码太长的话排版会乱套，但是复制到python里缩进还是正常的，所以不用担心。由于单个树洞的字数限制，我不得不分成多个树洞发，大家自行在python里拼起来吧……\n```python\n       def get_set_list(self,set_page_list):\n              #输入set_page_list，导出每一组套图的地址\n              set_list=[]\n              #顺便存一下每组套图的名字，保存文件名要用\n              set_name_list=[]\n              for set_page in set_page_list:\n                     req=requests.get(set_page,headers=self.headers)\n                     response=req.content\n                     response=etree.HTML(response)\n                     for i in response.xpath(\".//div[@class='title1']//a/@href\"):\n                            set_list.append('https://www.xiurenji.com'+i)\n                            pass\n                     temp_name=response.xpath(\".//div[@class='title1']//a/text()\")\n                     for j in range(int(len(temp_name)/2)):\n                            text=temp_name[j*2]+self.name+temp_name[j*2+1]\n                            set_name_list.append(text)\n                            pass\n                     pass\n              temp_num_max=len(set_list)\n              if (int(self.set_start%10)-1+self.set_num)>(temp_num_max-1):\n                     print('主人搜索的小姐姐没有'+str(self.set_num)+'组那么多套图哦，我默认下载全部啦~')\n                     self.set_num=='max'\n              if self.set_num=='max':\n                     set_list=set_list[int(self.set_start%10)-1:]\n                     set_name_list=set_name_list[int(self.set_start%10)-1:]\n                     pass\n              if self.set_num!='max':\n                     set_list=set_list[int(self.set_start%10)-1:int(self.set_start%10)-1+self.set_num]\n                     set_name_list=set_name_list[int(self.set_start%10)-1:int(self.set_start%10)-1+self.set_num]\n                     pass\n              self.set_list=set_list\n              self.set_name_list=set_name_list\n              return\n       def get_img_page_list(self,set_url):\n              #输入套图地址，下载该组套图的每一页地址\n              img_page_list=[]\n              req=requests.get(set_url,headers=self.headers)\n              response=req.content\n              response=etree.HTML(response)\n              temp=response.xpath(\".//div[@class='page']//a/@href\")\n              for i in temp[0:int((len(temp)/2))-1]:\n                     img_page_list.append('https://www.xiurenji.com'+i)\n                     pass\n              pass\n              self.img_page_list=img_page_list\n              return\n       def get_img_download_list(self,img_page_list):\n              #输入套图每一页地址表单，输出每一页三张图下载地址表单\n              img_download_list=[]\n              for img_page in img_page_list:\n                     req=requests.get(img_page,headers=self.headers)\n                     response=req.content\n                     response=etree.HTML(response)\n                     for i in response.xpath(\".//div[@class='img']//img/@src\"):\n                            img_download_list.append('https://www.xiurenji.com'+i)\n                            pass\n                     pass\n              self.img_download_list=img_download_list\n              return \n       def save_img(self,img_name,img_path,img_download):\n              #输入单个图片地址，在要求的路径中保存为指定名称\n              req=requests.get(img_download,headers=self.headers)\n              with open(img_path+'\\\\'+img_name+'.jpg', 'wb') as f:\n                     f.write(req.content)\n                     pass\n              return\n       def main_func(self):\n              self.get_set_page_list()\n              if(len(self.set_page_list)==0):\n                     print('没搜到这个小姐姐呢，是不是名字打错啦')\n                     return\n              self.get_set_list(self.set_page_list)\n              #创建模特的文件夹\n              if os.path.exists(self.model_path+'\\\\'+self.name)==False:\n                     model_path=self.model_path+'\\\\'+self.name\n                     os.mkdir(model_path)              \n              for i in range(self.set_num):\n                     #创建套图名称文件夹\n                     if os.path.exists(self.model_path+'\\\\'+self.name+'\\\\'+self.set_name_list[i])==False:\n                            set_path=self.model_path+'\\\\'+self.name+'\\\\'+self.set_name_list[i]\n                            os.mkdir(set_path)\n                     self.get_img_page_list(self.set_list[i])\n                     self.get_img_download_list(self.img_page_list)\n                     img_name=1\n                     for img_download in self.img_download_list:\n                            self.save_img(str(img_name),set_path,img_download)\n                            img_name=img_name+1\n                            pass\n                     if self.notice=='no':\n                            print('第'+str(i+1)+'组图下载完成啦，继续下载下一套咯，主人可以先去看看'+'\\n')\n                     if i==(self.set_num-1):\n                            print('全部下载完成啦，感谢使用~')\n                            return\n                     if self.notice=='yes':\n                            temp_notice=input('第'+str(i+1)+'组图下载完成啦，请问是否继续下载下一套？输入yes继续，输入no终止哦~'+'\\n')\n                            while (temp_notice!='yes')&(temp_notice!='no'):\n                                   temp_notice=input('啊咧？要输入yes或no的鸭'+'\\n')\n                            if temp_notice=='no':\n                                   print('感谢使用，呜喵~')\n                                   return\n                            else:\n                                   self.notice=input('下载完成下一套图后是否还要继续询问主人是否继续呢？仍要询问输入yes，不再询问输入no哦~'+'\\n')\n                                   while (self.notice!='yes')&(self.notice!='no'):\n                                          self.notice=input('啊咧？要输入yes或no的鸭'+'\\n')\n                                   print('收到，那我继续')\n                     pass\n              return\n       pass\n\n\n\n####运行完上面的爬虫主体后，就可以用下面的程序进行下载了，下面是一个范例，点击运行下面两行会下载糯美子的第6和第7套图（从第6套开始，下载两套）保存在指定文件夹（运行前请确定该文件夹存在！地址里面是两个斜杠！\nmodel1=modelspider(name='糯美子',model_path='E:\\\\文件夹A',set_start=6,set_num=2,notice='yes')       \nmodel1.main_func()\n####您可以通过修改其中的参数来下载自己喜欢的模特的套图", "timestamp": 1604067036, "type": "text", "updated_at": 1606782636, "url": "", "vote": {}}}